\documentclass[a4paper]{article}

\usepackage{amsmath, blindtext, float, graphicx, hyperref}
\graphicspath{ {./images/} }
\title{How Much Knowledge Can You Pack Into The Parameters of a Language Model?}
\author{Shubham Gupta}

\begin{document}
\maketitle
\section{Introduction}
\begin{itemize}
    \item This is a new paper which explores the limits of using their new T5 model in a context-free QA domain.
    \item As with the T5 model itself, it is very interesting to see these one-model-to-rule-them-all architectures as they exhibit some form of generalization.
    \item I found this paper from Adam's Roberts twitter thread which is available \href{https://twitter.com/ada_rob/status/1227062195671822336}{here} 
    \item \textbf{Core Idea}: This paper will test two main things:
    \begin{itemize}
        \item How well does the model create a knowledge base such that it can answer questions just based on this base and no other information.
        \item Do model with more parameters store more information? Measuring knowledge retreiving ability is used to check this point.
    \end{itemize}
\end{itemize}
\section{Paper Introduction}
\begin{itemize}
    \item 
\end{itemize}
\end{document}
