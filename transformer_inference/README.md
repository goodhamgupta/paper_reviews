# Transformer Inference

Collection of notes around improving transformer inference speed and efficiency. This will likely become a braindump of paper reviews, ideas and PoCs related to GPU acceleration for LLMs.
